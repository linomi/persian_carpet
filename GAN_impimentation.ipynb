{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0Yy5bg4JFnFR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa2m7R9tGUXr",
        "outputId": "300b3d20-2c1f-4dbc-a2a9-e0cff5dab344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1801 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# dataset\n",
        "b_size = 10\n",
        "dataset = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/data',\n",
        "                                                      labels=None,\n",
        "                                                      image_size= (512,256),\n",
        "                                                      shuffle=True,\n",
        "                                                      batch_size =b_size,\n",
        "                                                      color_mode = 'rgb',\n",
        "                                                      crop_to_aspect_ratio=False\n",
        "                                                      )\n",
        "def crop_image(image):\n",
        "    cropped_image = tf.image.crop_to_bounding_box(image,70,150,512, 256)\n",
        "    return cropped_image\n",
        "\n",
        "\n",
        "def normalize(ds):\n",
        "  ds = ds/255.0\n",
        "  return ds\n",
        "dataset = dataset.map(normalize)\n",
        "#dataset = dataset.map(crop_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjway5EDxgWG",
        "outputId": "fc27c2ef-1007-49c7-cdf1-b0b28c6a1958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FswcUKORFnFV"
      },
      "outputs": [],
      "source": [
        "latent_dim = 20\n",
        "## data augmentation model\n",
        "da_input = Input(shape=(512,256,3))\n",
        "x = RandomCrop(256,256)(da_input)\n",
        "x = RandomFlip()(x)\n",
        "x = RandomRotation(factor = ((0.4)),fill_mode = \"reflect\")(x)\n",
        "x = RandomZoom(0.2,0.2)(x)\n",
        "da_model = Model(da_input,x)\n",
        "\n",
        "## generative model\n",
        "gen_input = Input(shape = (latent_dim))\n",
        "x = Dense(8*8*8)(gen_input)\n",
        "x = Reshape((8,8,8))(x)\n",
        "x = Conv2DTranspose(16,(4,4),strides = 2 ,activation = 'linear',padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2DTranspose(32,(4,4),strides = 2 ,activation = 'linear',padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2DTranspose(64,(4,4),strides = 2 ,activation = 'linear',padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2DTranspose(128,(4,4),strides = 2 ,activation = 'linear',padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2DTranspose(256,(4,4),strides = 2 ,activation = 'linear',padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2DTranspose(512,(4,4),strides = 1 ,activation = 'linear',padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2DTranspose(3,(5,5),strides = 1 ,activation = 'linear',padding = 'same')(x)\n",
        "gen_model = Model(gen_input,x)\n",
        "\n",
        "# discriminator model\n",
        "dis_input = Input((256,256,3))\n",
        "x = Conv2D(512,kernel_size = 4,activation = 'relu',strides = 2,padding = 'same')(dis_input)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2D(256,kernel_size = 4,activation = 'relu',strides = 2,padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2D(128,kernel_size = 4,activation = 'relu',strides = 2,padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2D(64,kernel_size = 4,activation = 'relu',strides  = 2,padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2D(32,kernel_size = 4,activation = 'relu',strides  = 2,padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.2)(x)\n",
        "x = Conv2D(16,kernel_size = 4,activation = 'relu',strides  = 2,padding = 'same')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(1,activation = 'sigmoid')(x)\n",
        "dis_model = Model(dis_input,x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZlfafS_CFnFX"
      },
      "outputs": [],
      "source": [
        "class GAN(tf.keras.Model):\n",
        "    def __init__(self,da,gen,dis, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.da = da\n",
        "        self.gen = gen\n",
        "        self.dis = dis\n",
        "        self.dis_loss_tracker = tf.keras.metrics.Mean(name='dis_loss')\n",
        "        self.gen_loss_tracker = tf.keras.metrics.Mean(name='gen_loss')\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.dis_loss_tracker,\n",
        "                self.gen_loss_tracker]\n",
        "    def compile(self,optimizers, **kwargs):\n",
        "        super(GAN,self).compile(kwargs)\n",
        "        self.dis_opt = optimizers['dis_optimizer']\n",
        "        self.gen_opt = optimizers['gen_optimizer']\n",
        "\n",
        "    def train_step(self, data):\n",
        "        batch_size = tf.shape(data)[0]\n",
        "        random_in  = tf.random.normal(shape = (batch_size,latent_dim))\n",
        "        fake_generated = self.gen(random_in)\n",
        "        augmented_images = self.da(data)\n",
        "        whole_images = tf.concat([augmented_images,fake_generated],axis=0)\n",
        "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))],axis=0)\n",
        "        with tf.GradientTape() as tape:\n",
        "            pred = self.dis(whole_images)\n",
        "            dis_loss = tf.keras.losses.binary_crossentropy(labels,pred)\n",
        "\n",
        "        grads = tape.gradient(dis_loss,self.dis.trainable_weights)\n",
        "        self.dis_opt.apply_gradients(zip(grads, self.dis.trainable_weights))\n",
        "        self.dis_loss_tracker.update_state(dis_loss)\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "                                                shape=(batch_size,latent_dim))\n",
        "        misleading_labels = tf.ones((batch_size, 1))\n",
        "        with tf.GradientTape() as tape:\n",
        "            out = self.dis(self.gen(random_latent_vectors))\n",
        "            gen_loss = tf.keras.losses.binary_crossentropy(misleading_labels,out)\n",
        "        grads = tape.gradient(gen_loss,self.gen.trainable_weights)\n",
        "        self.gen_opt.apply_gradients(zip(grads, self.gen.trainable_weights))\n",
        "        self.gen_loss_tracker.update_state(gen_loss)\n",
        "\n",
        "        return {'dis_loss': self.dis_loss_tracker.result(),\n",
        "                'gen_loss': self.gen_loss_tracker.result(),\n",
        "                }\n",
        "gan = GAN(da_model,gen_model,dis_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBI36aR6GCHA",
        "outputId": "f0bc1daf-8558-45e4-cd2b-4b5075cfd7bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            " 79/181 [============>.................] - ETA: 5:02 - dis_loss: 0.6735 - gen_loss: 1.2465"
          ]
        }
      ],
      "source": [
        "     gan.compile(optimizers = {\n",
        "    'dis_optimizer':tf.keras.optimizers.Adam(),\n",
        "    'gen_optimizer':tf.keras.optimizers.Adam()\n",
        "})\n",
        "gan.fit(dataset,epochs = 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size = 8\n",
        "random_latent_vector = tf.random.normal(shape= (size,latent_dim))\n",
        "generated = np.array(gan.gen.predict(random_latent_vector))\n",
        "generated = (generated - generated.min())(generated.max() - generated.min())\n",
        "for i in range(1,size+1):\n",
        "  plt.subplot(4,2,i)\n",
        "  plt.axis('off')\n",
        "  plt.imshow()\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "3vulBXHaIike"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}